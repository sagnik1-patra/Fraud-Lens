{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "398cd2ec-e347-4ad2-8ad0-a9d15a346cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loading CSV: C:\\Users\\sagni\\Downloads\\FraudLens\\archive\\creditcard_2023.csv\n",
      "[INFO] Shape: (568630, 31)\n",
      "[INFO] Columns: ['id', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount', 'Class']\n",
      "[WRITE] Pickle  -> C:\\Users\\sagni\\Downloads\\FraudLens\\creditcard_2023.pkl\n",
      "[WRITE] HDF5    -> C:\\Users\\sagni\\Downloads\\FraudLens\\creditcard_2023.h5\n",
      "[WRITE] JSON    -> C:\\Users\\sagni\\Downloads\\FraudLens\\creditcard_2023.json\n",
      "[WRITE] YAML    -> C:\\Users\\sagni\\Downloads\\FraudLens\\creditcard_2023.yaml\n",
      "\n",
      "[DONE] All files saved in: C:\\Users\\sagni\\Downloads\\FraudLens\n",
      " - C:\\Users\\sagni\\Downloads\\FraudLens\\creditcard_2023.pkl\n",
      " - C:\\Users\\sagni\\Downloads\\FraudLens\\creditcard_2023.h5\n",
      " - C:\\Users\\sagni\\Downloads\\FraudLens\\creditcard_2023.json\n",
      " - C:\\Users\\sagni\\Downloads\\FraudLens\\creditcard_2023.yaml\n"
     ]
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# FraudLens — CSV -> PKL / H5 / JSON / YAML  (Robust IO)\n",
    "# ==========================================================\n",
    "# Input CSV:\n",
    "#   C:\\Users\\sagni\\Downloads\\FraudLens\\archive\\creditcard_2023.csv\n",
    "#\n",
    "# Outputs (all saved here):\n",
    "#   C:\\Users\\sagni\\Downloads\\FraudLens\n",
    "#     - creditcard_2023.pkl\n",
    "#     - creditcard_2023.h5\n",
    "#     - creditcard_2023.json\n",
    "#     - creditcard_2023.yaml\n",
    "#\n",
    "# Notes:\n",
    "# - HDF5 requires `tables` package and 64‑bit Python.\n",
    "# - YAML requires `pyyaml`.\n",
    "# - Script coerces types for HDF5, and converts NaN/NA -> None for JSON/YAML.\n",
    "# ==========================================================\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---------- Optional YAML ----------\n",
    "try:\n",
    "    import yaml\n",
    "    HAVE_YAML = True\n",
    "except Exception:\n",
    "    HAVE_YAML = False\n",
    "    print(\"[WARN] PyYAML not installed; YAML output will be skipped.\")\n",
    "\n",
    "# ---------- Paths ----------\n",
    "CSV_PATH = Path(r\"C:\\Users\\sagni\\Downloads\\FraudLens\\archive\\creditcard_2023.csv\")\n",
    "OUT_DIR  = Path(r\"C:\\Users\\sagni\\Downloads\\FraudLens\")\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "BASE_NAME = CSV_PATH.stem  # \"creditcard_2023\"\n",
    "PKL_PATH  = OUT_DIR / f\"{BASE_NAME}.pkl\"\n",
    "H5_PATH   = OUT_DIR / f\"{BASE_NAME}.h5\"\n",
    "JSON_PATH = OUT_DIR / f\"{BASE_NAME}.json\"\n",
    "YAML_PATH = OUT_DIR / f\"{BASE_NAME}.yaml\"\n",
    "\n",
    "# ---------- Load CSV ----------\n",
    "print(f\"[INFO] Loading CSV: {CSV_PATH}\")\n",
    "df = pd.read_csv(CSV_PATH, low_memory=False)\n",
    "print(\"[INFO] Shape:\", df.shape)\n",
    "print(\"[INFO] Columns:\", list(df.columns))\n",
    "\n",
    "# ---------- Helpers for clean serialization ----------\n",
    "def coerce_for_hdf(df_in: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert DataFrame to HDF5-friendly dtypes:\n",
    "      - numeric -> float64/int64/bool\n",
    "      - datetimes -> ISO strings (object)\n",
    "      - everything else -> object (string)\n",
    "    \"\"\"\n",
    "    g = df_in.copy()\n",
    "\n",
    "    # Convert pandas extension types to normal NumPy dtypes where reasonable\n",
    "    for col in g.columns:\n",
    "        s = g[col]\n",
    "        if pd.api.types.is_datetime64_any_dtype(s):\n",
    "            # Store datetimes as ISO strings for HDF5 simplicity\n",
    "            g[col] = s.dt.strftime(\"%Y-%m-%d %H:%M:%S\").astype(object)\n",
    "        elif pd.api.types.is_bool_dtype(s):\n",
    "            g[col] = s.astype(bool)\n",
    "        elif pd.api.types.is_integer_dtype(s):\n",
    "            # Use float64 if there are missing values (to avoid NA-int issues)\n",
    "            if s.isna().any():\n",
    "                g[col] = s.astype(\"float64\")\n",
    "            else:\n",
    "                g[col] = s.astype(\"int64\")\n",
    "        elif pd.api.types.is_float_dtype(s):\n",
    "            g[col] = s.astype(\"float64\")\n",
    "        else:\n",
    "            # Ensure plain Python strings for object columns\n",
    "            g[col] = s.astype(str).where(~s.isna(), None)\n",
    "\n",
    "    return g\n",
    "\n",
    "def records_for_json(df_in: pd.DataFrame) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Convert DataFrame to a list of JSON-serializable dicts:\n",
    "      - NaN/NA -> None\n",
    "      - NumPy scalars -> Python scalars\n",
    "    \"\"\"\n",
    "    g = df_in.copy()\n",
    "\n",
    "    # If any datetime dtype exists, convert to ISO string for JSON\n",
    "    for col in g.columns:\n",
    "        if pd.api.types.is_datetime64_any_dtype(g[col]):\n",
    "            g[col] = g[col].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "    g = g.where(pd.notna(g), None)\n",
    "    recs = g.to_dict(orient=\"records\")\n",
    "\n",
    "    # Ensure pure Python types (json can't handle numpy types)\n",
    "    out = []\n",
    "    for rec in recs:\n",
    "        clean = {}\n",
    "        for k, v in rec.items():\n",
    "            if isinstance(v, (np.floating,)):\n",
    "                clean[k] = float(v)\n",
    "            elif isinstance(v, (np.integer,)):\n",
    "                clean[k] = int(v)\n",
    "            elif isinstance(v, (np.bool_,)):\n",
    "                clean[k] = bool(v)\n",
    "            else:\n",
    "                clean[k] = v  # str, None, native numbers are fine\n",
    "        out.append(clean)\n",
    "    return out\n",
    "\n",
    "# ---------- Save: Pickle ----------\n",
    "print(f\"[WRITE] Pickle  -> {PKL_PATH}\")\n",
    "df.to_pickle(PKL_PATH)\n",
    "\n",
    "# ---------- Save: HDF5 ----------\n",
    "try:\n",
    "    df_h5 = coerce_for_hdf(df)\n",
    "    print(f\"[WRITE] HDF5    -> {H5_PATH}\")\n",
    "    df_h5.to_hdf(H5_PATH, key=\"data\", mode=\"w\", format=\"table\")\n",
    "except Exception as e:\n",
    "    print(f\"[WARN] Could not write HDF5: {e}\\n       Hint: pip install tables (64-bit Python)\")\n",
    "\n",
    "# ---------- Save: JSON ----------\n",
    "print(f\"[WRITE] JSON    -> {JSON_PATH}\")\n",
    "records = records_for_json(df)\n",
    "with open(JSON_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(records, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# ---------- Save: YAML ----------\n",
    "if HAVE_YAML:\n",
    "    try:\n",
    "        print(f\"[WRITE] YAML    -> {YAML_PATH}\")\n",
    "        with open(YAML_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "            yaml.safe_dump(records, f, allow_unicode=True, sort_keys=False)\n",
    "    except Exception as e:\n",
    "        print(f\"[WARN] Could not write YAML: {e}\")\n",
    "else:\n",
    "    print(\"[INFO] Skipping YAML (PyYAML not installed).\")\n",
    "\n",
    "print(\"\\n[DONE] All files saved in:\", OUT_DIR)\n",
    "print(\" -\", PKL_PATH)\n",
    "print(\" -\", H5_PATH)\n",
    "print(\" -\", JSON_PATH)\n",
    "if HAVE_YAML:\n",
    "    print(\" -\", YAML_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b259dec9-9ab7-4fd3-8b09-91879408a650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
