{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28946fd9-c327-40fc-870e-966ebbec798b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] --model MODEL --csv CSV --outdir OUTDIR [--threshold THRESHOLD]\n",
      "ipykernel_launcher.py: error: the following arguments are required: --model, --csv, --outdir\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3678: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# ==============================================\n",
    "# FraudLens — Batch Inference (score new CSVs)\n",
    "# ==============================================\n",
    "# Usage example (PowerShell):\n",
    "# python fraudlens_batch_infer.py ^\n",
    "#   --model \"C:\\Users\\sagni\\Downloads\\FraudLens\\fraudlens_model.pkl\" ^\n",
    "#   --csv   \"C:\\path\\to\\new_transactions.csv\" ^\n",
    "#   --outdir \"C:\\Users\\sagni\\Downloads\\FraudLens\"\n",
    "# ==============================================\n",
    "\n",
    "import re\n",
    "import json\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, confusion_matrix\n",
    "\n",
    "LABEL_PATTERNS = [\n",
    "    r\"\\bclass\\b\", r\"\\blabel\\b\", r\"\\btarget\\b\",\n",
    "    r\"\\bis[_\\-\\s]*fraud\\b\", r\"\\bfraud\\b\", r\"^y$\"\n",
    "]\n",
    "\n",
    "def find_label_col(cols):\n",
    "    norm = {c: re.sub(r\"[^a-z0-9]+\",\" \",str(c).lower()).strip() for c in cols}\n",
    "    for c, nc in norm.items():\n",
    "        for p in LABEL_PATTERNS:\n",
    "            if re.search(p, nc):\n",
    "                return c\n",
    "    return None\n",
    "\n",
    "def main():\n",
    "    ap = argparse.ArgumentParser()\n",
    "    ap.add_argument(\"--model\", required=True, help=\"Path to fraudlens_model.pkl\")\n",
    "    ap.add_argument(\"--csv\", required=True, help=\"CSV to score\")\n",
    "    ap.add_argument(\"--outdir\", required=True, help=\"Output directory\")\n",
    "    ap.add_argument(\"--threshold\", type=float, default=0.5, help=\"Decision threshold (default 0.5)\")\n",
    "    args = ap.parse_args()\n",
    "\n",
    "    model_path = Path(args.model)\n",
    "    csv_path   = Path(args.csv)\n",
    "    out_dir    = Path(args.outdir)\n",
    "    out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"[INFO] Loading model: {model_path}\")\n",
    "    pipe = joblib.load(model_path)\n",
    "\n",
    "    print(f\"[INFO] Reading: {csv_path}\")\n",
    "    df = pd.read_csv(csv_path, low_memory=False)\n",
    "    print(\"[INFO] Shape:\", df.shape)\n",
    "\n",
    "    # Auto-detect label if present (optional)\n",
    "    label_col = find_label_col(df.columns)\n",
    "    y_true = None\n",
    "    if label_col is not None:\n",
    "        y_raw = df[label_col]\n",
    "        if pd.api.types.is_numeric_dtype(y_raw):\n",
    "            y_true = (y_raw.astype(float) > 0).astype(int).values\n",
    "        else:\n",
    "            lower = y_raw.astype(str).str.lower().str.strip()\n",
    "            pos = {\"1\",\"true\",\"t\",\"yes\",\"y\",\"fraud\"}\n",
    "            y_true = lower.apply(lambda v: 1 if v in pos else 0).astype(int).values\n",
    "\n",
    "    # Use only numeric features (ignore label if numeric)\n",
    "    num_df = df.select_dtypes(include=[np.number]).copy()\n",
    "    if label_col in (num_df.columns if label_col else []):\n",
    "        X = num_df.drop(columns=[label_col])\n",
    "    else:\n",
    "        X = num_df\n",
    "    X = X.fillna(0.0).astype(float)\n",
    "\n",
    "    # Score\n",
    "    print(\"[INFO] Scoring...\")\n",
    "    probs = pipe.predict_proba(X.values)[:, 1]\n",
    "    preds = (probs >= args.threshold).astype(int)\n",
    "\n",
    "    # Build output frame\n",
    "    out = pd.DataFrame({\n",
    "        \"row_id\": np.arange(len(probs)),\n",
    "        \"prob_fraud\": probs,\n",
    "        \"y_pred\": preds\n",
    "    })\n",
    "    if label_col is not None:\n",
    "        out[\"y_true\"] = y_true\n",
    "\n",
    "    scored_csv = out_dir / \"fraudlens_scored.csv\"\n",
    "    out.to_csv(scored_csv, index=False)\n",
    "    print(f\"[SAVED] {scored_csv}\")\n",
    "\n",
    "    # Metrics if labels available\n",
    "    if y_true is not None:\n",
    "        roc_auc = roc_auc_score(y_true, probs)\n",
    "        pr_auc  = average_precision_score(y_true, probs)\n",
    "        cm      = confusion_matrix(y_true, preds, labels=[0,1])\n",
    "        report  = classification_report(y_true, preds, digits=4)\n",
    "\n",
    "        metrics = {\n",
    "            \"threshold\": args.threshold,\n",
    "            \"roc_auc\": float(roc_auc),\n",
    "            \"pr_auc\": float(pr_auc),\n",
    "            \"confusion_matrix\": {\n",
    "                \"tn\": int(cm[0,0]), \"fp\": int(cm[0,1]),\n",
    "                \"fn\": int(cm[1,0]), \"tp\": int(cm[1,1])\n",
    "            },\n",
    "            \"classification_report\": report\n",
    "        }\n",
    "        metrics_json = out_dir / \"fraudlens_scored_metrics.json\"\n",
    "        with open(metrics_json, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(metrics, f, indent=2)\n",
    "        print(f\"[SAVED] {metrics_json}\")\n",
    "    else:\n",
    "        print(\"[INFO] No label column detected — metrics not computed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15eae60f-de8f-4349-ad0e-44bc80f9b59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
